import streamlit as st
from openai import OpenAI
import base64
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
import sys
from dotenv import load_dotenv
import tempfile
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

import chat_LangGraph
import chat_Agent

load_dotenv()


#Chroma tenant ì˜¤ë¥˜ ë°©ì§€ ìœ„í•œ ì½”ë“œ
import chromadb
chromadb.api.client.SharedSystemClient.clear_system_cache()

#cache_resourceë¡œ í•œë²ˆ ì‹¤í–‰í•œ ê²°ê³¼ ìºì‹±í•´ë‘ê¸°
@st.cache_resource
def load_pdf(_file):
    with tempfile.NamedTemporaryFile(mode="wb", delete=False) as tmp_file:
        tmp_file.write(_file.getvalue())
        tmp_file_path = tmp_file.name
        #PDF íŒŒì¼ ì—…ë¡œë“œ
        loader = PyPDFLoader(file_path=tmp_file_path)
        pages = loader.load_and_split()
    return pages

#í…ìŠ¤íŠ¸ ì²­í¬ë“¤ì„ Chroma ì•ˆì— ì„ë² ë”© ë²¡í„°ë¡œ ì €ì¥
@st.cache_resource
def create_vector_store(_docs):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(_docs)
    vectorstore = Chroma.from_documents(split_docs, OpenAIEmbeddings(model='text-embedding-3-large'))
    return vectorstore

st.title("Chat with Image Support")
st.caption("ì™¼ìª½ì—ì„œ ë¬¸ì„œ ì„¤ì •ì‹œ ì±„íŒ…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
with st.sidebar:
    st.header("ğŸ”§ RAG ì“°ì¼ ë¬¸ì„œ ì„¤ì •")

    option = st.selectbox("Select Model Type", ("Just GPT", "LangGraph","AI Agent"))
    vectorinfo = st.text_input("Enter your PDF's Information")
    uploaded_file = st.file_uploader("Upload a PDF", type=["pdf"])





# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []




# PDF ì•ˆì˜¬ë¦¬ë©´ ì•ˆë‚˜ì˜´
if uploaded_file is not None and vectorinfo:
    
    
    if "retriever" not in st.session_state:
        pages = load_pdf(uploaded_file)
        vectorstore = create_vector_store(pages)
        retriever = vectorstore.as_retriever(search_kwargs={'k': 3})
        st.session_state.retriever = retriever
        
        graph , llm_with_tools = chat_Agent.make_agent(retriever,vectorinfo)
        st.session_state.graph = graph
        st.session_state.llm_with_tools = llm_with_tools
        st.session_state.config = {
            'configurable': {
                'thread_id': 'summarize_paper'
            }
        }
    



    # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ìœ ì € ì¸í’‹ í¼ ë§Œë“¤ê¸°
    with st.form("chat_form"):
        prompt = st.text_input("Enter your message:")
        uploaded_file = st.file_uploader("Upload an image (optional)", type=["jpg", "jpeg", "png"])
        col1, col2, col3 = st.columns([1, 4, 1]) 
        with col1:
            submit_button = st.form_submit_button("Send")
        with col3:
            clear_button = st.form_submit_button("clear")
            
    if clear_button:
        st.session_state.messages = []
        st.rerun()

    if submit_button:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì½˜í…ì¸ 
        message_content = []
        img = ""
        if prompt:
            message_content.append({"type": "text", "text": prompt})
        if uploaded_file is not None:
            # base64ë¡œ ì´ë¯¸ì§€ ì½ê¸°
            image_bytes = uploaded_file.read()
            image_type = uploaded_file.type  # e.g., 'image/jpeg'
            image_data = base64.b64encode(image_bytes).decode("utf-8")
            # ë©”ì„¸ì§€ ì½˜í…ì¸ ì— ì´ë¯¸ì§€ ë„£ê¸°
            message_content.append(
                {"type": "image_url", "image_url": {"url": f"data:{image_type};base64,{image_data}"}}
            )
            img = f"data:{image_type};base64,{image_data}"
        
        
        # session stateì— ì‚¬ìš©ì ë©”ì„¸ì§€ ì¶”ê°€ ( ë©”ì„¸ì§€ ì „ë‹¬ ê¸°ë¡ ì¶”ê°€ )
        st.session_state.messages.append({"role": "user", "content": prompt+"\n"+f"![]({img})"})
        
        with st.chat_message("user"):
            if prompt:
                st.markdown(prompt)
            if uploaded_file is not None:
                st.image(uploaded_file)
        
        
        
        
        
        
        if option == "Just GPT":
            # HumanMessage ë§Œë“¤ê¸°
            message = HumanMessage(content=message_content)

            # ì‘ë‹µë°›ê¸°
            client = ChatOpenAI(model='gpt-4o')
            response = client.invoke([message])
            
            # session stateì— AIë©”ì„¸ì§€ ì¶”ê°€ ( ë©”ì„¸ì§€ ì „ë‹¬ ê¸°ë¡ ì¶”ê°€ )
            st.session_state.messages.append({"role": "assistant", "content": response.content})
            with st.chat_message("assistant"):
                st.markdown(response.content)
                
                
        elif option == "LangGraph":
            initial_state = {'query_message': prompt, 'query_img' : img, "vector_store" : st.session_state.retriever , "vector_info" : vectorinfo }
            print(initial_state)
            print()
            answer = chat_LangGraph.graph.invoke(initial_state)
            # print(answer)
            print()
            print(answer["answer"]["type"])
            

            
            if answer["answer"]["type"] == "RAGtext":
                st.session_state.messages.append({"role": "assistant", "content": answer["answer"]["message"]})
                
                with st.chat_message("assistant"):
                    st.write(answer["answer"]["message"])
                    
                    with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                        for doc in answer['context']:
                            st.markdown(doc.metadata['source'], help=doc.page_content)
            
            elif answer["answer"]["type"] == "Webtext":
                st.session_state.messages.append({"role": "assistant", "content": answer["answer"]["message"]})
                
                with st.chat_message("assistant"):
                    st.write(answer["answer"]["message"])
                    
                    with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                        for doc in answer['context']:
                            st.markdown(doc['title'], help=doc['url'])
           
            elif answer["answer"]["type"] == "Notext":
                st.session_state.messages.append({"role": "assistant", "content": answer["answer"]["message"]})
                
                with st.chat_message("assistant"):
                    st.write(answer["answer"]["message"])
            
            else:
                text = f"""ì—¬ê¸° ìš”ì²­í•˜ì‹  ì´ë¯¸ì§€ì…ë‹ˆë‹¤!

![]({answer["answer"]["message"]})"""
                st.session_state.messages.append({"role": "assistant", "content": text })
                with st.chat_message("assistant"):
                    st.markdown(text)

 
 
        
        elif option == "AI Agent":
            
            message = HumanMessage(content=message_content)
            
            for chunk in st.session_state.graph.stream({'messages': [message], 'summary': '' , 'llm_with_tools' : st.session_state.llm_with_tools}, config=st.session_state.config, stream_mode='values'):
                chunk['messages'][-1].pretty_print()
                
            # ë””ë²„ê¹…ì„ ìœ„í•´ streamìœ¼ë¡œ ì¶œë ¥    
            # response = st.session_state.graph.invoke({'messages': [message], 'summary': '' , 'llm_with_tools' : st.session_state.llm_with_tools}, config=st.session_state.config)
              
            response = chunk['messages'][-1]
            
            # session stateì— AIë©”ì„¸ì§€ ì¶”ê°€ ( ë©”ì„¸ì§€ ì „ë‹¬ ê¸°ë¡ ì¶”ê°€ )
            st.session_state.messages.append({"role": "assistant", "content": response.content})

            with st.chat_message("assistant"):
                st.markdown(response.content)

